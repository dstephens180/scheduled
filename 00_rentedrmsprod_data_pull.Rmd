---
title: "rentedrmsprod"
---


# LIBRARIES
```{r setup, include=FALSE}
# sql connect
library(odbc)
library(DBI)
library(arrow)

# core packages
library(tidyverse)
library(dbplyr)
library(timetk)
library(tidyquant)
library(janitor)
library(lubridate)
library(stringi)
library(jsonlite)
library(tidyjson)
library(data.table)

# get data
library(fredr)
library(tidycensus)


date <- today()
options(scipen = 9999)


PROD_HOST    <- Sys.getenv("PROD_HOST")
PROD_DB_NAME <- Sys.getenv("PROD_DB_NAME")
PROD_ID      <- Sys.getenv("PROD_ID")
PROD_PW      <- Sys.getenv("PROD_PW")

prod_conn <- dbConnect(RMariaDB::MariaDB(),
                        host     = PROD_HOST,
                        dbname   = PROD_DB_NAME,
                        username = PROD_ID,
                        password = PROD_PW)

knitr::opts_chunk$set(echo = TRUE)
```




# 1.0 SQL EXTRACTS
## pull art_listings: geomarket & rates
```{sql connection=prod_conn, output.var="prod_art_listings"}
select cast(id as CHAR), cast(accounts_id as CHAR), cast(listing_name as CHAR), cast(geomarket as CHAR), cast(rates as CHAR)
from art_listings
where sync = 1
```


## pull art_accounts
```{sql connection=prod_conn, output.var="prod_art_accounts"}
select id, account_name, deactivation_reason, deactivation_date
from art_accounts
```


## pull art_listings: details only
```{sql connection=prod_conn, output.var="prod_art_listings_details"}
select cast(id as CHAR), cast(details as CHAR)
from art_listings
```






## Details: Spread & Prepare
```{r}
prod_art_listings_unnested <- prod_art_listings_details %>%
  rename(
    id      = `cast(id as CHAR)`,
    details = `cast(details as CHAR)`) %>% 
  
  # extract json details
  rowwise() %>%
  mutate(details_extract = list(fromJSON(details))) %>%
  ungroup() %>%
  
  # unnest wider
  unnest_wider(details_extract, simplify = T) %>%
  select(-details, -pricelabs, -listing_name, -airbnb_listing_id, -airbnb_user_id) %>%
  
  # unlist all columns that are still lists
  apply(2, function(y) sapply(y, function(x) paste(unlist(x), collapse = ", "))) %>%
  as_tibble() %>%
  
  # replace NA text with NA's
  mutate_all(~na_if(., "")) %>%
  mutate(across(where(is.character), na_if, "NA")) %>%
  
  # convert clean up columns
  mutate(id = as.integer(id),
         full_baths = as.numeric(full_baths) + as.numeric(half_baths)) %>%
  select(-half_baths, -baths) %>%
  mutate_at(c("beds", "guests", "rating", "reviews", "gap_stay", "latitude", "longitude", "min_stay", "bed_count", "min_stay_weekends", "min_stay_close", "min_stay_close_days"), as.numeric)


prod_art_listings_unnested %>% glimpse()

```


## Join listings & accounts
```{r}
prod_art_listings_cleaned <- prod_art_listings %>%
  rename(
    id           = `cast(id as CHAR)`,
    account_id   = `cast(accounts_id as CHAR)`,
    listing_name = `cast(listing_name as CHAR)`,
    geomarket    = `cast(geomarket as CHAR)`,
    rates        = `cast(rates as CHAR)`
  ) 


# both deactivation_reason/date should be NA/NULL values to be truly activated
prod_art_accounts_cleaned <- prod_art_accounts %>%
  filter(is.na(deactivation_date) & is.na(deactivation_reason)) %>%
  mutate(account_id = as.character(id),
         active     = "active") %>%
  select(account_id, account_name, active)



prod_listings_joined <- prod_art_listings_cleaned %>%
  left_join(prod_art_accounts_cleaned, by = "account_id") %>%
  filter(active == "active")
```





# 2.0 DATA PREP
## Geomarket Cleaning
```{r}
# small sample for testing
sample_tbl <- prod_listings_joined %>% head(10) %>% rowid_to_column()



# unnest & apply (over columns) and sapply (iterate over lists)
geomarket_cleaned_tbl <- prod_listings_joined %>%
  rowwise() %>%
  mutate(geomarket_extract = list(fromJSON(geomarket))) %>%
  ungroup() %>%
  unnest_wider(geomarket_extract) %>%
  apply(2, function(y) sapply(y, function(x) paste(unlist(x), collapse = ", "))) %>%
  as_tibble() %>%
  select(id, account_id, account_name, listing_name, full, comps, rates) %>%
  mutate(id = as.integer(id)) %>%
  filter(full != "",
         comps != "")



# stringr - no longer needed, as faster with apply/sapply
# geomarket_cleaned_tbl <- sample_tbl$geomarket %>%
#   str_replace_all("[^[:alnum:]\\_\\,\\s]", "") %>%
#   str_replace_all('full ', "") %>%
#   str_split(pattern = 'comps ', simplify = T) %>%
#   as_tibble() %>%
#   rename(full = V1,
#          comps = V2) %>%
#   bind_cols(sample_tbl) %>% 
#   select(id, account_id, account_name, listing_name, full, comps, avg_rate) %>%
#   mutate(id = as.integer(id)) %>%
#   filter(full != "null",
#          comps != "null")

write_rds(geomarket_cleaned_tbl, "00_data/geomarket_cleaned_tbl.rds")
geomarket_cleaned_tbl <- read_rds("00_data/geomarket_cleaned_tbl.rds")
```



## Join with details data
```{r}
data_full_cleaned_tbl <- geomarket_cleaned_tbl %>%
  left_join(prod_art_listings_unnested, by = "id")

data_full_cleaned_tbl %>% glimpse()
```









# 3.0 SAVE & DISCONNECT
## Save as parquet
```{r}
# live file in scheduled/00_data folder
write_parquet(data_full_cleaned_tbl, "C:\\Users\\DavidStephens\\Desktop\\Github\\scheduled\\00_data\\art_listing_ids_cleaned.parquet")

# live file for shiny in art_replica/shiny folder
write_parquet(data_full_cleaned_tbl, "C:\\Users\\DavidStephens\\Desktop\\Github\\artr_replica\\shiny\\art_listing_ids_cleaned.parquet")




# time-stamped archive file
write_parquet(data_full_cleaned_tbl, str_glue("C:\\Users\\DavidStephens\\Desktop\\Github\\scheduled\\00_data\\archive\\{date}_art_listing_ids_cleaned.parquet"))
```


## Disconnect SQL
```{r}
dbDisconnect(prod_conn)
```































































